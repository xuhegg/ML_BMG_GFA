{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import KFold,cross_validate\n",
    "from xgboost import XGBRegressor as xc\n",
    "from hyperopt import hp,fmin,tpe,Trials,partial\n",
    "from hyperopt.early_stop import no_progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read trainset\n",
    "df=pd.read_csv('../trainset/features_trainset_all.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df['pretty_formula']\n",
    "print('data shape：',df.shape)\n",
    "df.drop_duplicates(subset=['composition'], inplace=True)\n",
    "print('data shape：',df.shape)\n",
    "df=df.dropna(axis=1)\n",
    "df=df.dropna(axis=0)\n",
    "col_list=df.columns\n",
    "col_name=col_list[2:len(col_list)]\n",
    "featur=df[col_name].values\n",
    "target=df['D_max'].values\n",
    "X=featur\n",
    "Y=target\n",
    "del df['composition']\n",
    "print('data shape：',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalization\n",
    "y = df['D_max']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "#y.head()\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RF\n",
    "param_grid = {\n",
    "    'n_estimators':hp.quniform('n_estimators',50,550,5),\n",
    "    'max_features':hp.quniform('max_features',3,29,1),\n",
    "    'max_depth':hp.quniform('max_depth',8,55,1),\n",
    "    'min_samples_split':hp.quniform('min_samples_split',2,10,1),\n",
    "    'min_impurity_decrease':hp.quniform(\"min_impurity_decrease\",0,5,0.1)\n",
    "}\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    reg = RFR(n_estimators=int(params['n_estimators']),\n",
    "             max_depth=int(params['max_depth']),\n",
    "             max_features=int(params['max_features']),\n",
    "             min_samples_split=int(params['min_samples_split']),\n",
    "             min_impurity_decrease=params['min_impurity_decrease'],\n",
    "             random_state = 12138,\n",
    "             verbose = False,\n",
    "             n_jobs=10)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=12138)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='neg_root_mean_squared_error',cv=cv,\n",
    "                                    verbose=False,n_jobs=10,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))\n",
    "\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    \n",
    "    trials = Trials()\n",
    "    early_stop_fn = no_progress_loss(100) \n",
    "    params_best =fmin(hyperopt_objective,\n",
    "                     space = param_grid,\n",
    "                     algo = tpe.suggest,\n",
    "                     max_evals = max_evals,\n",
    "                     verbose = True,\n",
    "                     trials = trials,\n",
    "                     early_stop_fn = early_stop_fn\n",
    "                     )\n",
    "    print('\\n','best params:',params_best,'\\n')\n",
    "    return params_best,trials\n",
    "\n",
    "def hyperopt_validation(params):\n",
    "    reg = RFR(n_estimators=int(params['n_estimators']),\n",
    "             max_depth=int(params['max_depth']),\n",
    "             max_features=int(params['max_features']),\n",
    "             min_samples_split=int(params['min_samples_split']),\n",
    "             min_impurity_decrease=int(params['min_impurity_decrease']),\n",
    "             random_state =12138,\n",
    "             verbose = False,\n",
    "             n_jobs=-1)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26%|████████████▍                                  | 132/500 [04:45<13:14,  2.16s/trial, best loss: 0.778666724850233]\n",
    "\n",
    " best params: {'max_depth': 26.0, 'max_features': 10.0, 'min_impurity_decrease': 0.0, 'min_samples_split': 2.0, 'n_estimators': 280.0} \n",
    "\n",
    "0.7589432158826565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "param_grid = {\n",
    "    'C':hp.quniform('C',1,50,1),\n",
    "    'gamma':hp.quniform('gamma',0.1,0.45,0.005),\n",
    "    'epsilon':hp.quniform('epsilon',0,0.2,0.002)\n",
    "}\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    reg = SVR(C=int(params['C']),\n",
    "             epsilon=params['epsilon'],\n",
    "             gamma=params['gamma'],\n",
    "             kernel='rbf',\n",
    "             verbose = False\n",
    "             )\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=12138)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='neg_root_mean_squared_error',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))\n",
    "\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    trials = Trials()\n",
    "    early_stop_fn = no_progress_loss(100)\n",
    "    params_best =fmin(hyperopt_objective,\n",
    "                     space = param_grid,\n",
    "                     algo = tpe.suggest,\n",
    "                     max_evals = max_evals,\n",
    "                     verbose = True,\n",
    "                     trials = trials,\n",
    "                     early_stop_fn = early_stop_fn\n",
    "                     )\n",
    "    print('\\n','best params:',params_best,'\\n')\n",
    "    return params_best,trials\n",
    "\n",
    "def hyperopt_validation(params):\n",
    "    reg = SVR(C=int(params['C']),\n",
    "             epsilon=params['epsilon'],\n",
    "             gamma=params['gamma'],\n",
    "             kernel='rbf',\n",
    "             verbose = False)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500)\n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75%|██████████████████████████████████▋           | 377/500 [23:44<07:44,  3.78s/trial, best loss: 0.7807890462189855]\n",
    "\n",
    " best params: {'C': 5.0, 'epsilon': 0.03, 'gamma': 0.37} \n",
    "\n",
    "0.7524649155888021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGBoost\n",
    "param_grid_simple = {'n_estimators': hp.quniform(\"n_estimators\",150,450,3)\n",
    "                     ,\"learning_rate\": hp.quniform(\"learning_rate\",0.05,0.3,0.002)\n",
    "                     ,\"colsample_bytree\":hp.quniform(\"colsample_bytree\",0.3,1,0.1)\n",
    "                     ,\"colsample_bynode\":hp.quniform(\"colsample_bynode\",0.1,1,0.1)\n",
    "                     ,\"gamma\":hp.quniform(\"gamma\",0,15,0.2)\n",
    "                     ,\"reg_lambda\":hp.quniform(\"reg_lambda\",0,25,0.5)\n",
    "                     ,\"min_child_weight\":hp.quniform(\"min_child_weight\",0,50,0.5)\n",
    "                     ,\"max_depth\":hp.quniform(\"max_depth\",5,45,1)\n",
    "                     ,\"subsample\":hp.quniform(\"subsample\",0.5,1,0.1)\n",
    "                    }\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    reg = xc(n_estimators=int(params['n_estimators']),\n",
    "             max_depth=int(params['max_depth']),\n",
    "             reg_lambda=params['reg_lambda'],\n",
    "             learning_rate=params['learning_rate'],\n",
    "             subsample=params['subsample'],\n",
    "             colsample_bytree=params['colsample_bytree'],\n",
    "             colsample_bynode=params['colsample_bynode'],\n",
    "             gamma = params['gamma'],\n",
    "             min_child_weight=params['min_child_weight'],\n",
    "             objective='reg:squarederror',\n",
    "             random_state = 12138,\n",
    "             n_jobs=-1)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=12138)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='neg_root_mean_squared_error',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "\n",
    "    trials = Trials()\n",
    "    early_stop_fn = no_progress_loss(100)\n",
    "    params_best = fmin(hyperopt_objective\n",
    "                       , space = param_grid_simple\n",
    "                       , algo = tpe.suggest\n",
    "                       , max_evals = max_evals\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials\n",
    "\n",
    "def hyperopt_validation(params):\n",
    "    reg = xc(n_estimators=int(params['n_estimators']),\n",
    "             max_depth=int(params['max_depth']),\n",
    "             reg_lambda=params['reg_lambda'],\n",
    "             learning_rate=params['learning_rate'],\n",
    "             subsample=params['subsample'],\n",
    "             colsample_bytree=params['colsample_bytree'],\n",
    "             colsample_bynode=params['colsample_bynode'],\n",
    "             gamma = params['gamma'],\n",
    "             min_child_weight=params['min_child_weight'],\n",
    "             objective='reg:squarederror',\n",
    "             random_state = 12138,\n",
    "             n_jobs=-1)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 24%|██████████▋                                 | 121/500 [26:35<1:23:17, 13.19s/trial, best loss: 0.7304879093621787]\n",
    "\n",
    " \n",
    " best params:  {'colsample_bynode': 0.9, 'colsample_bytree': 0.9, 'gamma': 0.4, 'learning_rate': 0.056, 'max_depth': 30.0, 'min_child_weight': 1.0, 'n_estimators': 351.0, 'reg_lambda': 10.5, 'subsample': 0.8} \n",
    "\n",
    "0.783826239174134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators':hp.quniform('n_estimators',100,800,5),\n",
    "    'num_leaves':hp.quniform('num_leaves',10,400,5),\n",
    "    'learning_rate':hp.quniform('learning_rate',0.1,0.5,0.02),\n",
    "    'min_child_samples':hp.quniform('min_child_samples',1,40,1),\n",
    "    'reg_alpha':hp.quniform(\"reg_alpha\",0,10,0.5),\n",
    "    'reg_lambda':hp.quniform(\"reg_lambda\",0,100,2),\n",
    "    'subsample':hp.quniform(\"subsample\",0.5,1,0.1)\n",
    "}\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    reg = lgb.LGBMRegressor(\n",
    "             n_estimators=int(params['n_estimators']),\n",
    "             num_leaves=int(params['num_leaves']),\n",
    "             min_child_samples=int(params['min_child_samples']),\n",
    "             learning_rate=params['learning_rate'],\n",
    "             reg_alpha=params['reg_alpha'],\n",
    "             reg_lambda=params['reg_lambda'], \n",
    "             subsample = params['subsample'],\n",
    "             random_state = 12138,\n",
    "             verbose = int(False),\n",
    "             n_jobs=-1)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=12138)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='neg_root_mean_squared_error',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    trials = Trials()\n",
    "    early_stop_fn = no_progress_loss(100)\n",
    "    params_best =fmin(hyperopt_objective,\n",
    "                     space = param_grid,\n",
    "                     algo = tpe.suggest,\n",
    "                     max_evals = max_evals,\n",
    "                     verbose = True,\n",
    "                     trials = trials,\n",
    "                     early_stop_fn = early_stop_fn\n",
    "                     )\n",
    "    print('\\n','best params:',params_best,'\\n')\n",
    "    return params_best,trials\n",
    "\n",
    "def hyperopt_validation(params):\n",
    "    reg = lgb.LGBMRegressor(\n",
    "             n_estimators=int(params['n_estimators']),\n",
    "             num_leaves=int(params['num_leaves']),\n",
    "             min_child_samples=int(params['min_child_samples']),\n",
    "             learning_rate=params['learning_rate'],\n",
    "             reg_alpha=params['reg_alpha'],\n",
    "             reg_lambda=params['reg_lambda'], \n",
    "             subsample = params['subsample'],\n",
    "             random_state = 12138,\n",
    "             verbose = int(False),\n",
    "             n_jobs=-1)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best,trials = param_hyperopt(500) \n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 33%|███████████████▎                              | 167/500 [13:52<27:40,  4.99s/trial, best loss: 0.7369564970850893]\n",
    "\n",
    " best params: {'learning_rate': 0.12, 'min_child_samples': 6.0, 'n_estimators': 775.0, 'num_leaves': 385.0, 'reg_alpha': 0.5, 'reg_lambda': 92.0, 'subsample': 1.0} \n",
    "\n",
    "0.7768789919876828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fusion\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_scaled,y,train_size=0.8,random_state=12138)\n",
    "\n",
    "reg_svm = SVR(C=5,epsilon=0.03,gamma=0.37)\n",
    "reg_rf = RFR(max_depth=26,max_features=10,min_impurity_decrease=0,min_samples_split=2,n_estimators=280,random_state=12138)\n",
    "reg_xgb = xc(colsample_bynode=0.9,colsample_bytree=0.9,gamma=0.4,learning_rate=0.056,max_depth=30,\n",
    "         min_child_weight=1,n_estimators=351,reg_lambda=10.5,subsample=0.8,random_state=12138)\n",
    "reg_gbm = lgb.LGBMRegressor(learning_rate = 0.12,min_child_samples = 6,n_estimators = 775, \n",
    "         num_leaves =385,reg_alpha = 0.5,reg_lambda = 92,subsample = 1,random_state=12138)\n",
    "estimators = [('svm',reg_svm), ('rf',reg_rf), ('xgb',reg_xgb), ('lightgbm',reg_gbm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_hard =VotingRegressor(estimators).fit(X_train, Y_train)\n",
    "print('Test',VC_hard.score(X_test,Y_test))\n",
    "print('Train',VC_hard.score(X_train,Y_train))\n",
    "\n",
    "reg_rf.fit(X_train, Y_train)\n",
    "reg_xgb.fit(X_train, Y_train)\n",
    "reg_svm.fit(X_train, Y_train)\n",
    "reg_gbm.fit(X_train, Y_train)\n",
    "\n",
    "print('SVM',reg_svm.score(X_train, Y_train),reg_svm.score(X_test,Y_test))\n",
    "print('RF',reg_rf.score(X_train, Y_train),reg_rf.score(X_test,Y_test))\n",
    "print('XGB',reg_xgb.score(X_train, Y_train),reg_xgb.score(X_test,Y_test))\n",
    "print('LightGBM',reg_gbm.score(X_train, Y_train),reg_gbm.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "                'weight1': hp.quniform(\"weight1\",0,1,0.01),\n",
    "                'weight2': hp.quniform(\"weight2\",0,1,0.01),\n",
    "                'weight3': hp.quniform(\"weight3\",0,1,0.01),\n",
    "                'weight4': hp.quniform(\"weight4\",0,1,0.01)\n",
    "}\n",
    "\n",
    "def hyperopt_objective_weight(params):\n",
    "    weight1 = params['weight1']\n",
    "    weight2 = params['weight2']\n",
    "    weight3 = params['weight3']\n",
    "    weight4 = params['weight4']\n",
    "    weights = [weight1, weight2, weight3,weight4]\n",
    "\n",
    "    reg = VotingRegressor(estimators=estimators, n_jobs=-1,weights=weights)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=12138)\n",
    "    validation_loss = cross_validate(reg,X_scaled,y,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return -np.mean(abs(validation_loss['test_score']))\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "\n",
    "    trials = Trials()\n",
    "    early_stop_fn = no_progress_loss(50)\n",
    "    params_best = fmin(hyperopt_objective_weight\n",
    "                       , space = params_space\n",
    "                       , algo = tpe.suggest\n",
    "                       , max_evals = max_evals\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials\n",
    "\n",
    "def hyperopt_validation(params):\n",
    "    reg = VotingRegressor(estimators=estimators,n_jobs=-1,\n",
    "                          weights=[params[0]['weight1'],params[0]['weight2'],params[0]['weight3'],params[0]['weight4']])\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "    validation_loss = cross_validate(reg,X_test,Y_test,scoring='r2',cv=cv,\n",
    "                                    verbose=False,n_jobs=-1,error_score='raise')\n",
    "    return np.mean(abs(validation_loss['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best = param_hyperopt(300)\n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best = param_hyperopt(300)\n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_best = param_hyperopt(300)\n",
    "hyperopt_validation(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42%|█████████████████▎                       | 127/300 [1:32:10<2:05:33, 43.55s/trial, best loss: -0.8007935717455845]\n",
    "\n",
    " \n",
    " best params:  {'weight1': 0.47000000000000003, 'weight2': 0.01, 'weight3': 0.8300000000000001, 'weight4': 0.5} \n",
    "\n",
    "0.6483590637281165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = 0.47\n",
    "weight2 = 0.01\n",
    "weight3 = 0.83\n",
    "weight4 = 0.5\n",
    "\n",
    "weights = [weight1, weight2, weight3, weight4]\n",
    "\n",
    "weight_sum = weight1 + weight2 + weight3 + weight4\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_scaled,y,train_size=0.8,random_state=12138)\n",
    "Voting_soft_weight = VotingRegressor(estimators=estimators, n_jobs=-1,\n",
    "                                      weights=weights).fit(X_train, Y_train)\n",
    "print(Voting_soft_weight.score(X_train, Y_train))\n",
    "print(Voting_soft_weight.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Models|train_score|test_score|\n",
    "|:--:|:--:|:--:|\n",
    "|SVM|0.8757|0.7879|\n",
    "|RF|0.9670|0.7933|\n",
    "|XGB|0.9908|0.8064|\n",
    "|GBM|0.9994|0.8102|\n",
    "|avg|0.9802|0.8218|\n",
    "|opt|0.9851|0.8219|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8),dpi=200)\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "Test=[reg_svm.score(X_test,Y_test),reg_rf.score(X_test,Y_test),reg_xgb.score(X_test,Y_test),\n",
    "      reg_gbm.score(X_test,Y_test),Voting_soft_weight.score(X_test, Y_test)]\n",
    "\n",
    "x = [0,0.8,1.6,2.4,3.2]\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.bar(x, Test, width=width, label='$Test-R^{2}$',color='blue')  \n",
    "\n",
    "plt.ylabel(\"$R^{2}$\",fontsize=15)\n",
    "plt.xticks([0,0.8,1.6,2.4,3.2],['SVM','RF','XGBoost','LightGBM','Fusion'],fontsize=15)\n",
    "plt.xlim([-0.5,3.6])\n",
    "plt.ylim([0.75,0.83])\n",
    "plt.tick_params(axis=\"y\", direction=\"out\", which=\"major\", labelsize=15, length=5)\n",
    "plt.legend(fontsize=15,loc=2)\n",
    "plt.savefig('all_comparision_test_r2.tif',bbox_inches='tight',dpi=330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
